# DÃ©ploiement de la Stack ELK avec Docker et Filebeat

Ce projet met en place une pile ELK (Elasticsearch, Logstash, Kibana et Filebeat) via Docker afin de collecter, traiter et visualiser les logs gÃ©nÃ©rÃ©s par une application Python.

## ğŸ“Œ PrÃ©requis

- Docker
- Docker Compose

## ğŸš€ Configuration des Services

### 1ï¸âƒ£ Elasticsearch
- **Image** : `docker.elastic.co/elasticsearch/elasticsearch:7.11.1`
- **Ports** :
  - `9200` : API REST d'Elasticsearch
  - `9300` : Communication entre nÅ“uds Elasticsearch
- **Configuration** :
  - `discovery.type=single-node` : Mode mononÅ“ud
  - `ES_JAVA_OPTS=-Xms1g -Xmx1g` : Allocation de mÃ©moire Java
  - DÃ©sactivation de la sÃ©curitÃ© (`xpack.security.enabled=false`)

### 2ï¸âƒ£ Logstash
- **Image** : `docker.elastic.co/logstash/logstash:7.11.1`
- **Ports** :
  - `5044` : RÃ©ception des logs de Filebeat
  - `5045` : Port d'Ã©coute de Logstash
  - `9600` : Monitoring de Logstash
- **Volumes** :
  - `./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf`
- **DÃ©pendance** : ConnectÃ© Ã  Elasticsearch

### 3ï¸âƒ£ Kibana
- **Image** : `docker.elastic.co/kibana/kibana:7.11.1`
- **Port** : `5601` (interface web Kibana)
- **Configuration** :
  - Connexion Ã  Elasticsearch (`ELASTICSEARCH_HOSTS=http://elasticsearch:9200`)

### 4ï¸âƒ£ Filebeat
- **Image** : `docker.elastic.co/beats/filebeat:7.11.2`
- **Volumes** :
  - `./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml`
  - `./logs:/logs`
- **DÃ©pendances** : Envoie les logs Ã  Logstash et Elasticsearch

### ğŸŒ RÃ©seau
Tous les services sont interconnectÃ©s via un rÃ©seau Docker nommÃ© `elk`.

## ğŸ“‚ Fichiers de Configuration

### ğŸ›  `docker-compose.yml`
DÃ©crit les services Elasticsearch, Logstash, Kibana et Filebeat.

### ğŸ“ `send_logs.py`
Script Python simulant la gÃ©nÃ©ration de logs (`INFO`, `DEBUG`, `ERROR`).

### ğŸ“œ `filebeat.yml`
Configuration de Filebeat pour surveiller les logs locaux (`./logs/*.log`) et les envoyer Ã  Logstash.

### ğŸ”§ `logstash.conf`
Configuration de Logstash pour transformer et indexer les logs dans Elasticsearch.

## â–¶ï¸ DÃ©marrage des Services

1. **Cloner le dÃ©pÃ´t** :
   ```bash
   git clone <url-du-depot>
   cd <repertoire-du-depot>
   ```
2. **DÃ©marrer les services** :
   ```bash
   docker-compose up -d
   ```
3. **VÃ©rifier le statut des services** :
   - **Kibana** : [http://localhost:5601](http://localhost:5601)
   - **Elasticsearch** : [http://localhost:9200](http://localhost:9200)
   - **Logstash** : [http://localhost:9600](http://localhost:9600)

## ğŸ“¡ Simulation de Logs

1. ExÃ©cutez le script Python pour gÃ©nÃ©rer et enregistrer des logs :
   ```bash
   python send_logs.py
   ```
2. Les logs sont collectÃ©s par Filebeat, envoyÃ©s Ã  Logstash pour transformation, puis indexÃ©s dans Elasticsearch.

## ğŸ›‘ ArrÃªt des Services

Pour arrÃªter et supprimer tous les conteneurs :
```bash
docker-compose down
```

## âš™ï¸ Personnalisation
- Modifiez `filebeat.yml`, `logstash.conf` et `send_logs.py` selon vos besoins.
- Les logs sont stockÃ©s dans Elasticsearch sous lâ€™index `python-logs-YYYY.MM.dd`.

## ğŸ“š Documentation
- [Documentation Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)
- [Documentation Logstash](https://www.elastic.co/guide/en/logstash/current/index.html)
- [Documentation Kibana](https://www.elastic.co/guide/en/kibana/current/index.html)
- [Documentation Filebeat](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)

